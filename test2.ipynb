{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch as tc\n",
    "#from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Morphism(nn.Module):\n",
    "    def __init__ (self, name = 'Morphisme R^n --> E', dim_E = 1, neurons = 6):\n",
    "        print(f'[Model] name : {name}')\n",
    "        print(f'[Model] dim E : {dim_E}')\n",
    "        print(f'[Model] no. neurons per layers : {neurons}')\n",
    "        super(Morphism, self).__init__()\n",
    "        # layers for plus : E --> E\n",
    "        self.fc1 = nn.Linear(dim_E, neurons)\n",
    "        self.fc2 = nn.Linear(neurons, neurons)\n",
    "        self.fc3 = nn.Linear(neurons, neurons)\n",
    "        self.fc4 = nn.Linear(neurons, dim_E)\n",
    "\n",
    "        # dropout layer\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        output = self.fc4(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InverseMorphism(nn.Module):\n",
    "    def __init__ (self, name = 'Inverse E --> R^n', dim_E = 1, neurons = 6):\n",
    "        \n",
    "        print(f'[Model] name : {name}')\n",
    "        print(f'[Model] dim E : {dim_E}')\n",
    "        print(f'[Model] no. neurons per layers : {neurons}')\n",
    "        super(InverseMorphism, self).__init__()\n",
    "        # layers for plus : E --> E\n",
    "        self.fc1 = nn.Linear(dim_E, neurons)\n",
    "        self.fc2 = nn.Linear(neurons, neurons)\n",
    "        self.fc3= nn.Linear(neurons, neurons)\n",
    "        \n",
    "        self.fc4 = nn.Linear(neurons, dim_E)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        output = self.fc4(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoiBinaire(nn.Module):\n",
    "    def __init__ (self, name = 'Loi binaire ExE-->E', dim_E = 1, neurons = 6):\n",
    "        \n",
    "        print(f'[Model] name : {name}')\n",
    "        print(f'[Model] dim E : {dim_E}')\n",
    "        print(f'[Model] no. neurons per layers : {neurons}')\n",
    "        super(LoiBinaire, self).__init__()\n",
    "        # layers for plus : ExE --> E\n",
    "        self.fc1 = nn.Linear(2 * dim_E, neurons)\n",
    "        self.fc2 = nn.Linear(neurons, neurons)\n",
    "        self.fc3 = nn.Linear(neurons, neurons)\n",
    "        self.fc4 = nn.Linear(neurons, dim_E)\n",
    "    def forward(self, x, y):\n",
    "        z = torch.cat([x,y], axis=1) # [K,d], [K,d] ---> [K, 2*d]\n",
    "        z = self.fc1(z)\n",
    "        z = self.fc2(z)\n",
    "        z = self.fc3(z)\n",
    "        output = self.fc4(z)\n",
    "        return output\n",
    "# scalaire product of structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoiScalaire(nn.Module):\n",
    "    def __init__ (self, name = 'Loi Scalaire RxE-->E', dim_E = 1, neurons = 6):\n",
    "        \n",
    "        print(f'[Model] name : {name}')\n",
    "        print(f'[Model] dim E : {dim_E}')\n",
    "        print(f'[Model] no. neurons per layers : {neurons}')\n",
    "        super(LoiScalaire, self).__init__()\n",
    "        # layers for scaler : KxE --> E\n",
    "        \n",
    "\n",
    "        self.fc1 = nn.Linear(dim_E, neurons)\n",
    "        self.fc2 = nn.Linear(neurons, neurons)\n",
    "        self.fc3 = nn.Linear(neurons, neurons)\n",
    "        self.fc4 = nn.Linear(neurons, dim_E)\n",
    "        \n",
    "        # alpha est un  scalaire,  dim_E est la dimension de l'espace E\n",
    "        \n",
    "    def forward(self, alpha, x):\n",
    "        z = alpha * x # [K,1], [K,d] ---> [K, d]\n",
    "        z = self.fc1(z)\n",
    "        z = self.fc2(z)\n",
    "        z = self.fc3(z)\n",
    "        output = self.fc4(z)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vect_space(nn.Module):\n",
    "    def __init__ (self, K,  dim_E = 1 , neurons = 6 , name = 'Groupe (E,+)'):\n",
    "        super(Vect_space, self).__init__()\n",
    "        self.f    = Morphism(dim_E = dim_E, neurons = neurons)\n",
    "        self.fi   = InverseMorphism(dim_E = dim_E, neurons = neurons)\n",
    "        self.plus = LoiBinaire(dim_E = dim_E, neurons = neurons)\n",
    "        self.scalaire = LoiScalaire(dim_E = dim_E, neurons = neurons)\n",
    "        # losses\n",
    "        self.loss_1 = lambda x, y : torch.linalg.vector_norm(self.plus(x , y) - self.f( self.fi(x) + self.fi(y)) )**2\n",
    "        self.loss_2 = lambda alpha, x : torch.linalg.vector_norm(self.scalaire(alpha , x) - self.f( alpha*self.fi(x)) )**2\n",
    "\n",
    "        #  Total loss can be weighted \n",
    "        self.loss = lambda x, y, alpha : self.loss_1(x, y) + self.loss_2(alpha, x)\n",
    "        \n",
    "    def train(self, X, Y,alpha, optimizer, epoch):\n",
    "        self.f.train()\n",
    "        self.fi.train()\n",
    "        self.plus.train()\n",
    "        self.scalaire.train()\n",
    "        losses=[]\n",
    "        for i in range(epoch):\n",
    "            L1 = self.loss_1(X, Y)\n",
    "            L2 = self.loss_2(alpha, X)\n",
    "            loss = L1 + L2\n",
    "            #loss = loss.mean()\n",
    "            if i % 200 == 0:\n",
    "               print('Epoch {}/{} -\\t Loss 1: {:.6f}\\t Loss 2: {:.6f}\\t Total Loss: {:.6f}'.format(i, epoch, L1.item(), L2.item(), loss.item()))\n",
    "            \n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            losses.append(loss.item())\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np  \n",
    "def line(K, epsilon ):\n",
    "    \n",
    "    X = 0.3*torch.randn(K, 2).requires_grad_(False)\n",
    "    Y = 0.3*torch.randn(K, 2).requires_grad_(False)\n",
    "    alpha = torch.randn(K, 1).requires_grad_(False)\n",
    "    X[:,1] = X[:,0] + epsilon * torch.sin(X[:,0] / epislon ) # **3 + a*X[:,0] + b\n",
    "    Y[:,1] = Y[:,0] + epsilon * torch.sin(Y[:,0] / epislon) #**3 + a*Y[:,0] + b\n",
    "    return X, Y, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2000\n",
    "epislon = 0.1\n",
    "X,Y,alpha = line(K, epislon)\n",
    "dim = 2\n",
    "\n",
    "# on initialise le vecteur space\n",
    "G = Vect_space(K, dim_E = dim, neurons = 64)\n",
    "# on initialise l'optimiseur\n",
    "\n",
    "optimizer = optim.Adadelta(list(G.parameters()), lr=1e-3)\n",
    "# la loss\n",
    "losses = G.train(X,Y, alpha, optimizer, 1000)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(X[:,0], X[:,1], 'x', label='train X')\n",
    "plt.title('Training Data X')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# on affiche la loss \n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(losses)\n",
    "plt.title('Losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "B = torch.rand((K, 2))\n",
    "C = torch.rand((K, 2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Générer une valeur aléatoire pour B[0,0]\n",
    "for i in range(K):\n",
    "    B[i,1] = B[i,0] + epislon * torch.sin(B[i,0] / epislon )\n",
    "    C[i,1] = C[i,0] + epislon * torch.sin(C[i,0] / epislon )\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "print(B)\n",
    "\n",
    "print(C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Convert B and C to numpy arrays\n",
    "# Convert B and C to numpy arrays\n",
    "B_np = B.numpy()\n",
    "C_np = C.numpy()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'B_x': B_np[:, 0],\n",
    "    'B_y': B_np[:, 1],\n",
    "    'C_x': C_np[:, 0],\n",
    "    'C_y': C_np[:, 1],\n",
    "})\n",
    "\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Supposons que X soit une matrice 2D de taille (n, 2)\n",
    "# X = ...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], color='blue') \n",
    "\n",
    "\n",
    "\n",
    "colors_B = cm.rainbow(np.linspace(0, 1, B.shape[0]))\n",
    "colors_C = cm.rainbow(np.linspace(0, 1, C.shape[0]))\n",
    "\n",
    "plt.scatter(B[:, 0], B[:, 1], color=colors_B)\n",
    "for i in range(B.shape[0]):\n",
    "    plt.annotate(f'B_{i+1}', (B[i, 0], B[i, 1]))\n",
    "\n",
    "plt.scatter(C[:, 0], C[:, 1], color=colors_C)\n",
    "for i in range(C.shape[0]):\n",
    "    plt.annotate(f'C_{i+1}', (C[i, 0], C[i, 1]))\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "XXBC =  G.f(G.fi(B) + G.fi(C))\n",
    "YYBC = G.plus(B, C)\n",
    "\n",
    "for i in range(B.shape[0]):\n",
    "    plt.figure()\n",
    "    plt.scatter(X[:, 0], X[:, 1], color='blue') \n",
    "    plt.scatter(B[i, 0], B[i, 1], color='red', label=f'B_{i+1}')  \n",
    "    plt.annotate(f'B_{i+1}', (B[i, 0], B[i, 1]))\n",
    "    plt.scatter(C[i, 0], C[i, 1], color='green', label=f'C_{i+1}')\n",
    "    plt.annotate(f'C_{i+1}', (C[i, 0], C[i, 1]))\n",
    "    # Tracer le point XXBC[i]\n",
    "    plt.scatter(XXBC[i, 0].detach().numpy(), XXBC[i, 1].detach().numpy(), color='orange', label=f'f.fi(B) + f.fi(C)')\n",
    "    plt.annotate(f'f.fi(B) + f.fi(C)', (XXBC[i, 0].detach().numpy(), XXBC[i, 1].detach().numpy()))\n",
    "\n",
    "    # Tracer le point YYBC[i]\n",
    "    plt.scatter(YYBC[i, 0].detach().numpy(), YYBC[i, 1].detach().numpy(), color='pink', label=f'B⊕C')\n",
    "    plt.annotate(f'B⊕C', (YYBC[i, 0].detach().numpy(), YYBC[i, 1].detach().numpy()))\n",
    "    # Ajouter une légende au subplot\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "B = torch.rand((K, 2))\n",
    "alpha = torch.rand((K, 1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Générer une valeur aléatoire pour B[0,0]\n",
    "for i in range(K):\n",
    "    B[i,1] = B[i,0] + epislon * torch.sin(B[i,0] / epislon )\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "print(B)\n",
    "\n",
    "print(alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Convert B and C to numpy arrays\n",
    "# Convert B and C to numpy arrays\n",
    "B_np = B.numpy()\n",
    "alpha_np = alpha.numpy()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'B_x': B_np[:, 0],\n",
    "    'B_y': B_np[:, 1],\n",
    "    'alpha': C_np[:, 0],\n",
    "})\n",
    "\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XXBC =  G.f(alpha *G.fi(B))\n",
    "\n",
    "YYBC = G.scalaire(alpha, B)\n",
    "\n",
    "# print(XXBC)\n",
    "# print(YYBC)\n",
    "\n",
    "\n",
    "\n",
    "# calcul l'erreur entre les deux valeurs \n",
    "for i in range (len(XXBC)):\n",
    "    print(f'Erreur {i+1} : {torch.linalg.vector_norm(XXBC[i] - YYBC[i])}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "XXBC_list = [x.detach().numpy() for x in XXBC]\n",
    "YYBC_list = [y.detach().numpy() for y in YYBC]\n",
    "\n",
    "# Calculer l'erreur pour chaque couple et la stocker dans une liste\n",
    "erreur_list = [torch.linalg.vector_norm(XXBC[i] - YYBC[i]).item() for i in range(len(XXBC))]\n",
    "\n",
    "\n",
    "# Convertir les erreurs en notation scientifique\n",
    "erreur_list = ['{:.1e}'.format(erreur) for erreur in erreur_list]\n",
    "\n",
    "\n",
    "# Ajouter les listes comme nouvelles colonnes dans le DataFrame\n",
    "df['f(alpha * fi(B))'] = XXBC_list\n",
    "df['alpha * B'] = YYBC_list\n",
    "# Ajouter la colonne 'Erreur' à la fin du DataFrame\n",
    "df['Erreur'] = erreur_list\n",
    "\n",
    "df\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "XXBC =  G.f(alpha *G.fi(B))\n",
    "\n",
    "YYBC = G.scalaire(alpha, B)\n",
    "\n",
    "for i in range(B.shape[0]):\n",
    "    plt.figure()\n",
    "    plt.scatter(X[:, 0], X[:, 1], color='blue', label='X') \n",
    "    plt.scatter(B[i, 0], B[i, 1], color='red', label=f'B_{i+1}')  \n",
    "    plt.annotate(f'B_{i+1}', (B[i, 0], B[i, 1]))\n",
    "    plt.scatter(C[i, 0], C[i, 1], color='green', label=f'C_{i+1}')\n",
    "    plt.annotate(f'C_{i+1}', (C[i, 0], C[i, 1]))\n",
    "    # Tracer le point XXBC[i]\n",
    "    plt.scatter(XXBC[i, 0].detach().numpy(), XXBC[i, 1].detach().numpy(), color='orange', label=f'f(alpha * fi(B)')\n",
    "    plt.annotate(f'f( alpha * fi(B))', (XXBC[i, 0].detach().numpy(), XXBC[i, 1].detach().numpy()))\n",
    "\n",
    "    # Tracer le point YYBC[i]\n",
    "    plt.scatter(YYBC[i, 0].detach().numpy(), YYBC[i, 1].detach().numpy(), color='pink', label=f'B⊕C')\n",
    "    plt.annotate(f'B⊕C', (YYBC[i, 0].detach().numpy(), YYBC[i, 1].detach().numpy()))\n",
    "    # Ajouter une légende au subplot\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XXBC =  G.f(G.fi(B) + G.fi(C))\n",
    "\n",
    "YYBC = G.plus(B, C)\n",
    "\n",
    "# print(XXBC)\n",
    "# print(YYBC)\n",
    "\n",
    "\n",
    "\n",
    "# calcul l'erreur entre les deux valeurs \n",
    "for i in range (len(XXBC)):\n",
    "    print(f'Erreur {i+1} : {torch.linalg.vector_norm(XXBC[i] - YYBC[i])}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "XXBC_list = [x.detach().numpy() for x in XXBC]\n",
    "YYBC_list = [y.detach().numpy() for y in YYBC]\n",
    "\n",
    "# Calculer l'erreur pour chaque couple et la stocker dans une liste\n",
    "erreur_list = [torch.linalg.vector_norm(XXBC[i] - YYBC[i]).item() for i in range(len(XXBC))]\n",
    "\n",
    "\n",
    "# Convertir les erreurs en notation scientifique\n",
    "erreur_list = ['{:.1e}'.format(erreur) for erreur in erreur_list]\n",
    "\n",
    "\n",
    "# Ajouter les listes comme nouvelles colonnes dans le DataFrame\n",
    "df['f.fi(B) + f.fi(C)'] = XXBC_list\n",
    "df['B⊕C'] = YYBC_list\n",
    "# Ajouter la colonne 'Erreur' à la fin du DataFrame\n",
    "df['Erreur'] = erreur_list\n",
    "\n",
    "df\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
